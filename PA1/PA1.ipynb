{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "Part 1: \n",
    "When k = 1, the classifier performs the best on validation data\n",
    "Test error rate when k = 1 is 0.094\n",
    "################################################################\n",
    "\n",
    "k=1\n",
    "Training error: 0.0\n",
    "Validation error: 0.081\n",
    "    \n",
    "k=5 \n",
    "Training error: 0.0565\n",
    "Validation error: 0.096\n",
    "    \n",
    "k=9\n",
    "Training error: 0.07\n",
    "Validation error: 0.107\n",
    "    \n",
    "k=15\n",
    "Training error: 0.0895\n",
    "Validation error: 0.11\n",
    "    \n",
    "    \n",
    "################################################################\n",
    "Part 2: \n",
    "When k = 15, the classifier performs the best on validation data\n",
    "Test error rate when k = 1 is 0.299\n",
    "\n",
    "By projection, the classifier is less acurate, but the time used to \n",
    "run the program also decreases.\n",
    "################################################################\n",
    "\n",
    "For k =  1  training error:  0.0\n",
    "For k =  1  validate error:  0.32\n",
    "\n",
    "For k =  3  training error:  0.1595\n",
    "For k =  3  validate error:  0.304\n",
    "\n",
    "For k =  5  training error:  0.195\n",
    "For k =  5  validate error:  0.302\n",
    "    \n",
    "For k =  9  training error:  0.2325\n",
    "For k =  9  validate error:  0.302\n",
    "    \n",
    "For k =  15  training error:  0.2525\n",
    "For k =  15  validate error:  0.295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# extract data from train_file\n",
    "train_file = open(\"pa1train.txt\", \"r\")\n",
    "train_line = [line.strip() for line in train_file]\n",
    "train_line = [line.split() for line in train_line]\n",
    "tr_line = []\n",
    "for x in train_line:\n",
    "    tr_line.append([int (i) for i in x ])\n",
    "\n",
    "train_feature = [(y[:-1] ,y[-1]) for y in tr_line]\n",
    "train_vector = np.asarray([y[:-1] for y in tr_line])\n",
    "train_label = [x[-1] for x in tr_line]\n",
    "#print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from test_file\n",
    "test_file = open(\"pa1test.txt\", \"r\")\n",
    "test_line = [line.strip() for line in test_file]\n",
    "test_line = [line.split() for line in test_line]\n",
    "t_line = []\n",
    "for x in test_line:\n",
    "    t_line.append([int (i) for i in x ])\n",
    "test_feature = [(x[:-1] ,x[-1]) for x in t_line]\n",
    "test_vector = np.asarray([y[:-1] for y in t_line])\n",
    "test_label = [x[-1] for x in t_line]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from validate_file\n",
    "validate_file = open(\"pa1validate.txt\", \"r\")\n",
    "validate_line = [line.strip() for line in validate_file]\n",
    "validate_line = [line.split() for line in validate_line]\n",
    "v_line = []\n",
    "for x in validate_line:\n",
    "    v_line.append([int (i) for i in x ])\n",
    "validate_feature = [(x[:-1] ,x[-1]) for x in v_line]\n",
    "validate_vector = np.asarray([y[:-1] for y in v_line])\n",
    "validate_label = [x[-1] for x in v_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    return sum([(a[i]-b[i])**2 for i in range(len(a))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the distance between training points and training points\n",
    "dist_train = []\n",
    "for data_in,original_label in train_feature: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_feature:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the distance between training points and validate points\n",
    "dist_validate = []\n",
    "for data_in,original_label in validate_feature: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_feature:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_validate.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the distance between training points and test points\n",
    "dist_test = []\n",
    "for data_in,original_label in test_feature: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_feature:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting \n",
    "for li in dist_train:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in dist_validate:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in dist_test:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def most_common(lst):\n",
    "    maxCount = 0\n",
    "    for x in lst:\n",
    "        maxCount = max(lst.count(x),maxCount)\n",
    "    labelSet = set()\n",
    "    for x in lst:\n",
    "        if(lst.count(x) == maxCount): labelSet.add(x)\n",
    "    return random.choice(list(labelSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k):\n",
    "    # training \n",
    "    train_predict = []\n",
    "    for v in dist_train:\n",
    "        temp = []\n",
    "        i = 0\n",
    "        while(i < k):\n",
    "            temp.append(v[i][1])\n",
    "            i = i+1\n",
    "        train_predict.append(most_common(temp))\n",
    "    # calculating training error \n",
    "    errorNum = 0;\n",
    "    for i in range(len(train_predict)):\n",
    "        if(train_predict[i] != train_label[i]):\n",
    "            #print(train_predict[i],train_label[i])\n",
    "            errorNum += 1\n",
    "    errorRate = errorNum/len(train_label)\n",
    "    print(\"For k = \",k,\" training error: \",errorRate)\n",
    "    \n",
    "    # validating \n",
    "    validate_predict = []\n",
    "    for v in dist_validate:\n",
    "        temp = []\n",
    "        i = 0\n",
    "        while(i < k):\n",
    "            temp.append(v[i][1])\n",
    "            i = i+1\n",
    "        validate_predict.append(most_common(temp))\n",
    "    # calculating validate error \n",
    "    errorNum = 0;\n",
    "    for i in range(len(validate_predict)):\n",
    "        if(validate_predict[i] != validate_label[i]):\n",
    "            #print(train_predict[i],train_label[i])\n",
    "            errorNum += 1\n",
    "    errorRate = errorNum/len(validate_label)\n",
    "    print(\"For k = \",k,\" validate error: \",errorRate)\n",
    "    \n",
    "    # testing \n",
    "    test_predict = []\n",
    "    for v in dist_test:\n",
    "        temp = []\n",
    "        i = 0\n",
    "        while(i < k):\n",
    "            temp.append(v[i][1])\n",
    "            i = i+1\n",
    "        test_predict.append(most_common(temp))\n",
    "    # calculating validate error \n",
    "    errorNum = 0;\n",
    "    for i in range(len(test_predict)):\n",
    "        if(test_predict[i] != test_label[i]):\n",
    "            #print(train_predict[i],train_label[i])\n",
    "            errorNum += 1\n",
    "    errorRate = errorNum/len(test_label)\n",
    "    print(\"For k = \",k,\" test error: \",errorRate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  1  training error:  0.0\n",
      "For k =  1  validate error:  0.082\n",
      "For k =  1  test error:  0.094\n"
     ]
    }
   ],
   "source": [
    "knn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  3  training error:  0.0415\n",
      "For k =  3  validate error:  0.096\n",
      "For k =  3  test error:  0.09\n"
     ]
    }
   ],
   "source": [
    "knn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  5  training error:  0.0555\n",
      "For k =  5  validate error:  0.095\n",
      "For k =  5  test error:  0.097\n"
     ]
    }
   ],
   "source": [
    "knn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  9  training error:  0.0695\n",
      "For k =  9  validate error:  0.103\n",
      "For k =  9  test error:  0.101\n"
     ]
    }
   ],
   "source": [
    "knn(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  15  training error:  0.09\n",
      "For k =  15  validate error:  0.101\n",
      "For k =  15  test error:  0.117\n"
     ]
    }
   ],
   "source": [
    "knn(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data from projection.txt\n",
    "proj_file = open(\"projection.txt\", \"r\")\n",
    "proj_line = [line.strip() for line in proj_file]\n",
    "proj_line = [line.split() for line in proj_line]\n",
    "projection = []\n",
    "for x in proj_line:\n",
    "    projection.append([float (i) for i in x ])\n",
    "#projection = np.asarray(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get projection of train, validate and test data on projection.txt\n",
    "train_proj = np.matmul(train_vector,projection)\n",
    "validate_proj = np.matmul(validate_vector,projection)\n",
    "test_proj = np.matmul(test_vector,projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair projection with corresponding labels \n",
    "train_proj_label = []\n",
    "test_proj_label = []\n",
    "validate_proj_label = []\n",
    "for i in range(len(tr_line)):\n",
    "    train_proj_label.append((train_proj[i] ,tr_line[i][-1]))\n",
    "for i in range(len(t_line)):\n",
    "    test_proj_label.append((test_proj[i] ,t_line[i][-1]))\n",
    "for i in range(len(v_line)):\n",
    "    validate_proj_label.append((validate_proj[i] ,v_line[i][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat steps in Q1\n",
    "# calculate all the distance between training points and training points \n",
    "dist_train = []\n",
    "for data_in,original_label in train_proj_label: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_proj_label:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_train.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate all the distance between training points and validate points\n",
    "dist_validate = []\n",
    "for data_in,original_label in validate_proj_label: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_proj_label:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_validate.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the distance between training points and test points\n",
    "dist_test = []\n",
    "for data_in,original_label in test_proj_label: \n",
    "    temp = []\n",
    "    for data_train,predict_label in train_proj_label:\n",
    "        temp += [(np.linalg.norm(np.asarray(data_in) - np.asarray(data_train)),predict_label)]\n",
    "        #temp += [(dist(data_in,data_train),predict_label)]\n",
    "    dist_test.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting \n",
    "for li in dist_train:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in dist_validate:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for li in dist_test:\n",
    "    li.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  1  training error:  0.0\n",
      "For k =  1  validate error:  0.32\n",
      "For k =  1  test error:  0.314\n"
     ]
    }
   ],
   "source": [
    "knn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  3  training error:  0.1545\n",
      "For k =  3  validate error:  0.304\n",
      "For k =  3  test error:  0.299\n"
     ]
    }
   ],
   "source": [
    "knn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  5  training error:  0.195\n",
      "For k =  5  validate error:  0.302\n",
      "For k =  5  test error:  0.296\n"
     ]
    }
   ],
   "source": [
    "knn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  9  training error:  0.2325\n",
      "For k =  9  validate error:  0.302\n",
      "For k =  9  test error:  0.289\n"
     ]
    }
   ],
   "source": [
    "knn(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k =  15  training error:  0.2525\n",
      "For k =  15  validate error:  0.295\n",
      "For k =  15  test error:  0.299\n"
     ]
    }
   ],
   "source": [
    "knn(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
